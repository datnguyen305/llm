from transformers import AutoTokenizer, AutoModelForCausalLM

class TextGenerator:
    def __init__(self, context, question, threshold_cons=-2, max_retries=3):
        self.tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-1.5B-Instruct")
        self.model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-1.5B-Instruct")
        self.context = context
        self.question = question
        self.THRESHOLD_CONS = threshold_cons  # Ng∆∞·ª°ng consistency
        self.MAX_RETRIES = max_retries        # S·ªë l·∫ßn th·ª≠ l·∫°i t·ªëi ƒëa
        self.response = None
        self.consistency_score = None

    def _create_messages(self, is_regenerate=False, previous_score=None):
        """T·∫°o messages cho chat template"""
        system_message = "B·∫°n l√† m·ªôt tr·ª£ l√Ω h·ªØu √≠ch. Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng b·∫±ng ti·∫øng Vi·ªát, ch·ªâ d·ª±a tr√™n th√¥ng tin trong ph·∫ßn Context ƒë∆∞·ª£c cung c·∫•p."
        
        if is_regenerate and previous_score is not None:
            user_content = f"""Ng·ªØ c·∫£nh: {self.context}
C√¢u h·ªèi: {self.question}

L·∫ßn tr·∫£ l·ªùi tr∆∞·ªõc c√≥ ƒëi·ªÉm consistency th·∫•p ({previous_score:.4f} < {self.THRESHOLD_CONS}). 
H√£y tr·∫£ l·ªùi l·∫°i m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n h∆°n, d·ª±a ch·∫∑t ch·∫Ω v√†o th√¥ng tin trong ng·ªØ c·∫£nh."""
        else:
            user_content = f"Ng·ªØ c·∫£nh: {self.context}\nC√¢u h·ªèi: {self.question}\nH√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n ng·ªØ c·∫£nh"

        return [
            {"role": "system", "content": system_message},
            {"role": "user", "content": user_content}
        ]

    def _generate_text(self, messages):
        """Sinh text t·ª´ messages"""
        # T·∫°o input t·ª´ template chat
        inputs = self.tokenizer.apply_chat_template(
            messages,
            add_generation_prompt=True,
            tokenize=True,
            return_dict=True,
            return_tensors="pt",
        ).to(self.model.device)

        outputs = self.model.generate(
            **inputs,
            max_new_tokens=2042,         # Gi·∫£m xu·ªëng ƒë·ªÉ tr√°nh qu√° d√†i
            do_sample=True,            
            top_p=0.9,                 
            temperature=0.7            
        )

        # L·∫•y ph·∫ßn text m·ªõi sinh
        generated_answer = self.tokenizer.decode(
            outputs[0][inputs["input_ids"].shape[-1]:],
            skip_special_tokens=True
        )

        return generated_answer.strip()

    def generate_response(self):
        """Sinh response l·∫ßn ƒë·∫ßu ti√™n"""
        messages = self._create_messages(is_regenerate=False)
        self.response = self._generate_text(messages)
        return self.response

    def regenerate_response(self, consistency_score):
        """
        Regenerate response n·∫øu consistency score th·∫•p
        
        Args:
            consistency_score (float): ƒêi·ªÉm consistency hi·ªán t·∫°i
            
        Returns:
            str: Response m·ªõi ƒë∆∞·ª£c sinh ra
        """
        self.consistency_score = consistency_score
        
        # Ki·ªÉm tra n·∫øu ƒëi·ªÉm ƒë√£ ƒë·ªß t·ªët
        if consistency_score >= self.THRESHOLD_CONS:
            print(f"‚úÖ Consistency score ({consistency_score:.4f}) ƒë√£ ƒë·∫°t y√™u c·∫ßu!")
            return self.response
        
        print(f"üîÑ Regenerating... (Score: {consistency_score:.4f} < {self.THRESHOLD_CONS})")
        
        # T·∫°o messages m·ªõi cho regeneration
        messages = self._create_messages(is_regenerate=True, previous_score=consistency_score)
        new_response = self._generate_text(messages)
        
        self.response = new_response
        return new_response

    def generate_with_quality_check(self, evaluator_func=None):
        """
        Sinh response v·ªõi ki·ªÉm tra ch·∫•t l∆∞·ª£ng t·ª± ƒë·ªông
        
        Args:
            evaluator_func: Function ƒë·ªÉ ƒë√°nh gi√° consistency score
                          Signature: func(question, answer) -> float
                          
        Returns:
            tuple: (final_response, final_score, num_retries)
        """
        if evaluator_func is None:
            # N·∫øu kh√¥ng c√≥ evaluator, ch·ªâ sinh response th∆∞·ªùng
            return self.generate_response(), None, 0
        
        # Sinh response ƒë·∫ßu ti√™n
        current_response = self.generate_response()
        retries = 0

        while retries < self.MAX_RETRIES:
            # ƒê√°nh gi√° consistency
            score = evaluator_func(self.question, current_response)
            print(f"Attempt {retries + 1}: Consistency = {score:.4f}")
            
            # N·∫øu ƒë·∫°t y√™u c·∫ßu, return
            if score >= self.THRESHOLD_CONS:
                self.consistency_score = score
                return current_response, score, retries
            
            # N·∫øu ch∆∞a ƒë·∫°t v√† c√≤n l·∫ßn th·ª≠, regenerate
            if retries < self.MAX_RETRIES - 1:
                current_response = self.regenerate_response(score)
                retries += 1
                print(f"Regenerated Response: {current_response}\n Retries: {retries}")
            else:
                # H·∫øt l·∫ßn th·ª≠, return response cu·ªëi c√πng
                print(f"‚ö†Ô∏è ƒê√£ th·ª≠ {self.MAX_RETRIES} l·∫ßn, gi·ªØ response cu·ªëi c√πng")
                self.consistency_score = score
                return current_response, score, retries
        
        return current_response, self.consistency_score, retries
